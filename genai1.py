import torch
from torch import nn, optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import torchvision
import numpy as np
import random

# Transform the images (normalize them)
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Load MNIST dataset
dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

# Display some sample images from the dataset
def show_samples(dataloader):
    images, labels = next(iter(dataloader))
    plt.figure(figsize=(10,4))
    for i in range(8):
        plt.subplot(2, 4, i+1)
        img = images[i].squeeze() * 0.5 + 0.5  # unnormalize image
        plt.imshow(img, cmap="gray")
        plt.title(f"Label: {labels[i].item()}")
        plt.axis('off')
    plt.show()

# Show samples of the MNIST dataset
show_samples(dataloader)

# Define the Generator class
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(100, 256),          # 100-dim input to 256-dim output
            nn.LeakyReLU(0.2),            # activation function
            nn.BatchNorm1d(256),          # normalize layer
            nn.Linear(256, 512),          # 256-dim to 512-dim
            nn.LeakyReLU(0.2),            # activation function
            nn.BatchNorm1d(512),          # normalize layer
            nn.Linear(512, 784),          # 512-dim to 784-dim (28x28 image flattened)
            nn.Tanh()                     # output activation function
        )

    def forward(self, z):
        return self.model(z)

# Define the Discriminator class
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(784, 512),          # 784-dim (28x28 flattened) to 512-dim
            nn.LeakyReLU(0.2),            # activation function
            nn.Linear(512, 256),          # 512-dim to 256-dim
            nn.LeakyReLU(0.2),            # activation function
            nn.Linear(256, 1),            # 256-dim to 1 output (real or fake)
            nn.Sigmoid()                  # output activation function (0 or 1)
        )

    def forward(self, x):
        return self.model(x)

# Instantiate the Generator and Discriminator
generator = Generator()
discriminator = Discriminator()

# Loss function and Optimizers
criterion = nn.BCELoss()
g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)
d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)

# Training Loop
epochs = 50
for epoch in range(epochs):
    for real_imgs, _ in dataloader:
        batch_size = real_imgs.size(0)
        real_imgs = real_imgs.view(batch_size, -1)  # Flatten the images

        # Labels for real and fake images
        real_labels = torch.ones(batch_size, 1)
        fake_labels = torch.zeros(batch_size, 1)

        # ---------------------------
        # Train Discriminator
        # ---------------------------
        # Train with real images
        d_optimizer.zero_grad()
        real_outputs = discriminator(real_imgs)
        d_loss_real = criterion(real_outputs, real_labels)

        # Train with fake images generated by the Generator
        z = torch.randn(batch_size, 100)  # Random noise
        fake_imgs = generator(z)
        fake_outputs = discriminator(fake_imgs.detach())  # Detach to avoid updating generator
        d_loss_fake = criterion(fake_outputs, fake_labels)

        # Total Discriminator loss
        d_loss = d_loss_real + d_loss_fake
        d_loss.backward()
        d_optimizer.step()

        # ---------------------------
        # Train Generator
        # ---------------------------
        g_optimizer.zero_grad()
        fake_outputs = discriminator(fake_imgs)
        g_loss = criterion(fake_outputs, real_labels)  # We want the generator to make real-like images

        g_loss.backward()
        g_optimizer.step()

    # Print loss values for tracking progress
    print(f"Epoch [{epoch+1}/{epochs}], Discriminator Loss: {d_loss.item()}, Generator Loss: {g_loss.item()}")

# Function to display generated images after training
def show_generated_images(generator, n_images=25):
    z = torch.randn(n_images, 100)  # Generate random noise
    fake_images = generator(z).view(-1, 1, 28, 28)  # Generate images from noise
    grid = torchvision.utils.make_grid(fake_images, nrow=5, normalize=True)  # Arrange in a grid
    plt.imshow(np.transpose(grid.cpu(), (1, 2, 0)))  # Convert to RGB for displaying
    plt.axis('off')
    plt.show()

# Show generated images
show_generated_images(generator)



# --- SAMPLE OUTPUT FORMAT ---
# ✅ Console Output (sample):
# Epoch [1/50], Discriminator Loss: 0.6931, Generator Loss: 0.6928
# Epoch [2/50], Discriminator Loss: 0.6814, Generator Loss: 0.7297
# ...
# After training, a 5x5 grid of generated images (28x28 MNIST digits) is displayed.

# --- WORKING OF THE PROGRAM ---
# 1. Load the MNIST dataset using torchvision
# 2. Define Generator:
#    - Takes a 100-dim noise vector and produces a 784-dim image (flattened 28x28)
#    - Uses fully connected layers + BatchNorm + Tanh
# 3. Define Discriminator:
#    - Takes a 784-dim image and outputs a single probability (real/fake)
#    - Uses fully connected layers + LeakyReLU + Sigmoid
# 4. Train GAN:
#    a. Train Discriminator on:
#       - Real MNIST images (label 1)
#       - Fake images from Generator (label 0)
#    b. Train Generator:
#       - Generate fake images
#       - Try to fool Discriminator (label as 1)
# 5. After training, generate and show synthetic digits

# --- HOW CALCULATIONS WORK (LOSS & FLOW) ---
# - Generator tries to **minimize** the probability of Discriminator correctly classifying fake images
# - Discriminator tries to **maximize** the accuracy of distinguishing real vs fake
# - Binary Cross Entropy Loss (BCELoss) is used:
#     D_loss = BCE(D(x_real), 1) + BCE(D(G(z_fake)), 0)
#     G_loss = BCE(D(G(z_fake)), 1)
# - `z = torch.randn(batch_size, 100)` generates random noise for Generator input
# - `view(batch_size, -1)` flattens images
# - `detach()` prevents generator gradients from affecting D during D training

# --- REQUIRED PYTHON LIBRARIES (INSTALL WITH pip) ---
# Make sure you install the following before running the code:
# ✅ PyTorch:             pip install torch torchvision
# ✅ Matplotlib:          pip install matplotlib
# ✅ NumPy:               pip install numpy

# You can install all at once:
# pip install torch torchvision matplotlib numpy

# --- NOTE ---
# - You are using a simple GAN (fully connected, not CNN-based).
# - Tanh activation is used in the generator to output values between -1 and 1 (to match normalized images).
# - This GAN trains on grayscale 28x28 handwritten digits (MNIST).
# - For better results, you can add training checkpoints or save models.

# --- END OF COMMENTS ---
